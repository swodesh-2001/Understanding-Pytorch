{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a model and building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be building a neural network in pytorch. we will be using `torch.nn` for this task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets,transforms "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the neural network class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets create a Neural class, that takes input of image size 28*28 and produces forward pass output passed through relu activiated two layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neural(nn.Module):\n",
    "    def __init__(self) :\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_layers = nn.Sequential(\n",
    "            nn.Linear(28*28 , 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512,512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512,10),\n",
    "        )\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_layers(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`nn.Flatten` does similar to what `np.flatten` does. It flattens out high dimensional data to a single dimension.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 784])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_images = torch.rand(3,28,28)\n",
    "flattener = nn.Flatten()\n",
    "flattened_output =  flattener(random_images)\n",
    "flattened_output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the `nn.Flatten()` maintained the dimension `0`. If we want to flatten all the dimension it can be done as "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2352])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_flattened = nn.Flatten(start_dim=0, end_dim= -1)(random_images)\n",
    "all_flattened.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another layer is the `nn.Linear`. It applies a linear transformation to the input with its strored weight. Lets see the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 1])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_transformer = nn.Linear(in_features= 28*28 , out_features = 1 )\n",
    "linear_output = linear_transformer(flattened_output)\n",
    "linear_output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It produces output of three random images data. Lets see the weight "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0084,  0.0268, -0.0272, -0.0034,  0.0301,  0.0123,  0.0088,  0.0163,\n",
       "         0.0015,  0.0108,  0.0120,  0.0250, -0.0353,  0.0132,  0.0314, -0.0161,\n",
       "        -0.0232, -0.0316,  0.0037,  0.0003], grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_transformer.weight[0,:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 784])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_transformer.weight.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And another is nn.ReLU , it just applies relu function to the input.\n",
    "\n",
    "![relu](./images/relu.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To combine all the function together, we use Sequential. the data will be passed in the order as defined."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets create a model and compute the `forward pass`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_layers): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = Neural().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have created two random images, one is a random numpy array and another is random tensor. When we pass the random image to the model.flatten(). We can see that the numpy array isn't supported so we must pass tensor to the function. And the `device` the tensor is created should also match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7b1df51ad7e0>"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "Y = np.random.rand(1,28,28) # we can't pass this to torch flatten function. We need a tensor\n",
    "X = torch.rand(1, 28, 28, device=device)\n",
    "plt.imshow(X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 784])"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_to_model = model.flatten(X)\n",
    "input_to_model.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 10])"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_output = model.linear_layers(input_to_model)\n",
    "final_output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus our random image, final output is the output of the 10 final units. Now if we are doing a classification task we pass it to the softmax function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1087, 0.0978, 0.1009, 0.1058, 0.0985, 0.0944, 0.1000, 0.0938, 0.1041,\n",
      "         0.0960]], grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "final_probability = nn.Softmax(dim= 1)(final_output)\n",
    "print(final_probability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 10])"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_probability.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get a tensor that contains our probability of each class. So lets ge the index of max probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0])"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_class = final_probability.argmax(1)\n",
    "predicted_class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automatic  Differentitation with torch.autograd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We know once we do forward pass, we get the output now to update the weights of the Linear layers, which we saw earlier. For each layer there is weight connecting the previous nodes and current nodes as well as there are bias terms. To update them we take derivative of the `Cost` function with the weights and calulate the gradient which will be further used to update them.\n",
    "\n",
    "\n",
    "To do this , pytorch has differentiation calulation enginer called torch.autograd which automatically computes the gradient for the computation graph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets peform a simple forward pass, which will be based on the fig shown below :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![computation_graph](./images/computation_graph.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets assume the input consist of data having 5 feature.\n",
    "\n",
    "And there is only one output node\n",
    "\n",
    "![perceptron_image](./images/perceptorn.png)\n",
    "\n",
    "\n",
    "We will conside the activation function to be just linear in this case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand(1,5)\n",
    "w = torch.rand(5,1 ,requires_grad= True )\n",
    "b = torch.rand(1 , requires_grad= True)\n",
    "z = x @ w + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets say our actual target is `y` = 1.5. and lets take absolute error as loss metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.tensor(1.5)\n",
    "loss = y - z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now if we want to find the gradient of `w` and `b` with the obtained loss. It can be done through loss.backward() . It calculates the $`\\frac{\\partial L}{\\partial w}`$ and $`\\frac{\\partial L}{\\partial b}`$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets see the gradients of the weight matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0905],\n",
       "        [-0.3120],\n",
       "        [-0.2455],\n",
       "        [-0.0203],\n",
       "        [-0.0054]])"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly lets see the gradients of the bias matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.])"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note \n",
    "> \n",
    "    We can only obtain the grad properties for the leaf nodes of the computational graph, which have requires_grad property set to True. For all other nodes in our graph, gradients will not be available.\n",
    "\n",
    "    We can only perform gradient calculations using backward once on a given graph, for performance reasons. If we need to do several backward calls on the same graph, we need to pass retain_graph=True to the backward call.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we train the network, we only need to predict. So, we no longer need to calculate the gradient .Thus, we do the following :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "z = torch.matmul(x, w)+b\n",
    "print(z.requires_grad)\n",
    "\n",
    "with torch.no_grad():\n",
    "    z = torch.matmul(x, w)+b\n",
    "print(z.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use `z.detach()` as well to make the `requires_grad` set to `False`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensor Gradients and Jacobian Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we have output function as arbitrary tensor instead of scalar loss funciton. In this case , we can calulate the jacobian product instead of the actual gradient.\n",
    "\n",
    "For a vector function \\(\\vec{y} = f(\\vec{x})\\), where \\(\\vec{x} = \\langle x_1, \\ldots, x_n \\rangle\\) and \\(\\vec{y} = \\langle y_1, \\ldots, y_m \\rangle\\), a gradient of \\(\\vec{y}\\) with respect to \\(\\vec{x}\\) is given by the **Jacobian matrix**:\n",
    "\n",
    "```math\n",
    "J = \\begin{pmatrix}\n",
    "\\frac{\\partial y_1}{\\partial x_1} & \\cdots & \\frac{\\partial y_1}{\\partial x_n} \\\\\n",
    "\\vdots & \\ddots & \\vdots \\\\\n",
    "\\frac{\\partial y_m}{\\partial x_1} & \\cdots & \\frac{\\partial y_m}{\\partial x_n}\n",
    "\\end{pmatrix}\n",
    "```\n",
    "\n",
    "Instead of computing the Jacobian matrix itself, PyTorch allows you to compute the **Jacobian Product** \\(\\vec{v}^T \\cdot J\\) for a given input vector \\(\\vec{v} = \\langle v_1, \\ldots, v_m \\rangle\\). This is achieved by calling `backward` with \\(\\vec{v}\\) as an argument. The size of \\(\\vec{v}\\) should be the same as the size of the original tensor, with respect to which we want to compute the product.\n",
    "```\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 1., 0.]], requires_grad=True)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp = torch.eye(4, 5, requires_grad=True)\n",
    "inp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function is $`y = f(x) =  (x+1)^2  `$. Now to theoritically check the gradient value.   \n",
    "\n",
    "if we take differentiation the derivative function is $`y' = f'(x) =  2*(x+1)  `$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4., 1., 1., 1., 1.],\n",
       "        [1., 4., 1., 1., 1.],\n",
       "        [1., 1., 4., 1., 1.],\n",
       "        [1., 1., 1., 4., 1.]], grad_fn=<PowBackward0>)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = (inp+1).pow(2)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First call\n",
      "tensor([[4., 2., 2., 2., 2.],\n",
      "        [2., 4., 2., 2., 2.],\n",
      "        [2., 2., 4., 2., 2.],\n",
      "        [2., 2., 2., 4., 2.]])\n"
     ]
    }
   ],
   "source": [
    "out.backward(torch.ones_like(out), retain_graph=True)\n",
    "print(f\"First call\\n{inp.grad}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus gradient is calculated properly, for the first element value was 1. Its output was 4 and its gradient was 4 , which is correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Second call\n",
      "tensor([[8., 4., 4., 4., 4.],\n",
      "        [4., 8., 4., 4., 4.],\n",
      "        [4., 4., 8., 4., 4.],\n",
      "        [4., 4., 4., 8., 4.]])\n"
     ]
    }
   ],
   "source": [
    "out.backward(torch.ones_like(out), retain_graph=True)\n",
    "print(f\"\\nSecond call\\n{inp.grad}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above we are passing new input which is all one. i.e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.ones_like(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Call after zeroing gradients\n",
      "tensor([[4., 2., 2., 2., 2.],\n",
      "        [2., 4., 2., 2., 2.],\n",
      "        [2., 2., 4., 2., 2.],\n",
      "        [2., 2., 2., 4., 2.]])\n"
     ]
    }
   ],
   "source": [
    "inp.grad.zero_()\n",
    "out.backward(torch.ones_like(out), retain_graph=True)\n",
    "print(f\"\\nCall after zeroing gradients\\n{inp.grad}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So each time we call the backward, the gradient are accumulated. if we do retain_graph"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ekbana",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
